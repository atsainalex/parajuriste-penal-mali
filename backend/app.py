import os
import json
import faiss
import numpy as np
from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI

# -------------------------
# CONFIG
# -------------------------
API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=API_KEY)

EMBED_MODEL = "text-embedding-3-large"
CHAT_MODEL = "gpt-4.1"

# -------------------------
# CHARGEMENT BASE DE CONNAISSANCE
# -------------------------
FAISS_PATH = "knowledge/faiss.index"
EMB_PATH = "knowledge/embeddings.npy"
PASS_PATH = "knowledge/passages.json"

if not os.path.exists(FAISS_PATH):
    print("[INFO] ‚ö†Ô∏è Aucune base vectorielle trouv√©e ‚Äî r√©ponses sans contexte.")
    FAISS = None
    PASSAGES = []
else:
    print("[INFO] Base de connaissance FAISS charg√©e.")
    FAISS = faiss.read_index(FAISS_PATH)
    EMBEDDINGS = np.load(EMB_PATH)
    with open(PASS_PATH, "r", encoding="utf-8") as f:
        PASSAGES = json.load(f)

# -------------------------
# FASTAPI
# -------------------------
app = FastAPI()

from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],  
    allow_headers=["*"],
)

@app.options("/chat")
async def preflight_handler():
    return {}

class Query(BaseModel):
    prompt: str
    mode: str = "public"


# -------------------------
# EMBEDDING
# -------------------------
def embed_text(text: str):
    r = client.embeddings.create(
        model=EMBED_MODEL,
        input=text
    )
    return np.array(r.data[0].embedding, dtype="float32")


# -------------------------
# RECHERCHE DANS FAISS
# -------------------------
def search_knowledge(query: str, k: int = 5):
    if FAISS is None:
        return []

    q_emb = embed_text(query).reshape(1, -1)
    _, idx = FAISS.search(q_emb, k)

    results = []
    for i in idx[0]:
        if i < len(PASSAGES):
            results.append(PASSAGES[i]["text"])
    return results


# -------------------------
# FORMATAGE DE LA R√âPONSE (10px entre lignes)
# -------------------------
def format_final_answer(text: str) -> str:
    """
    - Ajoute un saut de ligne propre
    - Espacement de 5px entre chaque phrase
    - Nettoie les mauvaises citations
    """

    if not text:
        return text

    # 1. Interdiction des guides citoyens
    forbidden = [
        "Guide Citoyen du Code p√©nal",
        "Guide citoyen du Code p√©nal",
        "Guide Citoyen du Code de proc√©dure p√©nale",
        "Guide citoyen du Code de proc√©dure p√©nale",
        "guide citoyen",
        "Guide citoyen"
    ]
    for f in forbidden:
        text = text.replace(f, "")

    # 2. D√©couper par phrases avec regex
    import re
    sentences = re.split(r'(?<=[.!?])\s+', text)

    result = ""
    for s in sentences:
        if s.strip():
            result += s.strip() + "<br><div style='margin-bottom:10px;'></div>"

    # Nettoyage
    while "<br><div style='margin-bottom:10px;'></div><br>" in result:
        result = result.replace(
            "<br><div style='margin-bottom:10px;'></div><br>",
            "<br><div style='margin-bottom:10px;'></div>"
        )

    return result.strip()


# -------------------------
# PROMPT STRICT Z√âRO HALLUCINATION
# -------------------------
def build_prompt(user_prompt: str, mode: str, context_blocks: list):

    context_text = "\n\n".join(f"- {c}" for c in context_blocks)

    return f"""
Tu es **Parajuriste P√©nal Mali**, assistant juridique strict.

Fourni plus de d√©tails quand tu donnes des r√©ponses aux question qu'on te pose, soit empathique tout en √©tant professionnel en repondant, r√©agit comme un Avocat conseil.

üõë **R√àGLE ABSOLUE :**
Tu dois r√©pondre UNIQUEMENT avec les extraits ci-dessous provenant :
- du Code p√©nal 2024
- du Code de proc√©dure p√©nale 2024
- de la Constitution 2023
- des documents fournis dans la base vectorielle

Cite aussi les sources des articles provenant des documents :
- du Code p√©nal 2024
- du Code de proc√©dure p√©nale 2024
- de la Constitution 2023

Pr√©cise de quels documents proviennent les articles que tu cites.

Met en gras tous les articles que tu cites

Si un article ou une r√®gle ne figure PAS dans les extraits FAISS, tu √©cris :
"Je ne trouve pas cet article dans la base de connaissances fournie."

---

üìö **EXTRAITS DISPONIBLES :**
{context_text}

---

üéØ **FORMAT OBLIGATOIRE DE LA R√âPONSE :**

1. üü¢ R√©ponse directe  
2. üìò Explication simple  
3. ‚öñÔ∏è Preuve juridique  
4. üí° Conseil pratique  
5. ‚ö†Ô∏è Avertissement  

---

‚ùì **QUESTION :**
{user_prompt}
"""


# -------------------------
# ROUTE PRINCIPALE /chat
# -------------------------
@app.post("/chat")
def chat(q: Query):

    mode = q.mode
    question = q.prompt

    # 1. Recherche dans la base locale
    context = search_knowledge(question)

    # 2. Construction du prompt final
    final_prompt = build_prompt(question, mode, context)

    # 3. Appel OpenAI
    response = client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[
            {"role": "system", "content": "Tu es Parajuriste P√©nal Mali, assistant strict, z√©ro hallucination."},
            {"role": "user", "content": final_prompt}
        ]
    )

    raw_answer = response.choices[0].message.content

    # 4. Formatage HTML avec espacement 10px
    formatted = format_final_answer(raw_answer)

    # 5. R√©ponse propre
    return {
        "reply": formatted,
        "mode": mode,
        "sources": context
    }
